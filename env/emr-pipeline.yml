AWSTemplateFormatVersion: 2010-09-09
Description: Cloudformation Template to spin up prod pipeline for EMR lab

Parameters:
  masterNodeType:
    Type: String
    Default: m5.large
  workerNodeType:
    Type: String
    Default: m5.2xlarge
  workerNodeCount:
    Type: String
    Default: 5

Resources:

  # Cloud9 env for code review

  cloud9Env:
    Type: AWS::Cloud9::EnvironmentEC2
    Properties:
      AutomaticStopTimeMinutes: 20160
      InstanceType: t2.micro

  # Custom resource for generating a random ID to prefix all resources and avoid conflicts
  RandomId:
    Type: "AWS::CloudFormation::CustomResource"
    Properties:
      Operation: lower
      Number: 6
      ServiceToken: !GetAtt RandomStringFunction.Arn

  RandomStringFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import traceback
          import string
          import random
          import uuid
          import json
          import http.client
          from urllib.parse import urlparse


          def random_string():
              return ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(6))

          def send_response(request, response):

              if 'ResponseURL' in request and request['ResponseURL']:
                  url = urlparse(request['ResponseURL'])
                  print(url)
                  if len(url.path) != 0:
                      body = json.dumps(response)
                      https = http.client.HTTPSConnection(url.hostname)
                      https.request('PUT', url.path+'?'+url.query, body)

              return response

          def handler(event, context):
              response = {
                  'StackId': event['StackId'],
                  'RequestId': event['RequestId'],
                  'LogicalResourceId': event['LogicalResourceId'],
                  'Status': 'SUCCESS'
              }
              print(event)

              if 'PhysicalResourceId' in event:
                  response['PhysicalResourceId'] = event['PhysicalResourceId']
              else:
                  response['PhysicalResourceId'] = str(uuid.uuid4())

              if event['RequestType'] == 'Delete':
                  return send_response(event, response)

              rs = random_string()
              response['Data']   = { 'RandomString': rs.lower() }
              print(response)
              return send_response(event,response)

      Handler: index.handler
      Runtime: python3.6
      Role: !GetAtt RandomStringFunctionExecutionRole.Arn

  RandomStringFunctionExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: [lambda.amazonaws.com]
            Action: ['sts:AssumeRole']
      Path: /
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: ['logs:*']
                Resource: 'arn:aws:logs:*:*:*'

  # the random prefix used for naming all resources stored in SSM
  randomID:
    Type: "AWS::SSM::Parameter"
    Properties:
      Description: Random ID for prefixing automated.
      Type: String
      Value: !GetAtt RandomId.RandomString

  # The network infrastructure for the EMR cluster (public subnet)
  emrInternetGateway:
    Type: AWS::EC2::InternetGateway

  emrVpc:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsSupport: true
      EnableDnsHostnames: true

  emrVpcGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref emrVpc
      InternetGatewayId: !Ref emrInternetGateway

  emrRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref emrVpc

  enrRoute:
    Type: AWS::EC2::Route
    Properties:
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref emrInternetGateway
      RouteTableId: !Ref emrRouteTable

  emrSubnet:
    Type: AWS::EC2::Subnet
    Properties:
      AvailabilityZone: !Sub '${AWS::Region}a'
      VpcId: !Ref emrVpc
      CidrBlock: 10.0.1.0/16
      MapPublicIpOnLaunch: true

  emrSubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref emrRouteTable
      SubnetId: !Ref emrSubnet

  emrMasterSecGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security for master node
      VpcId: !Ref emrVpc

  emrWorkerSecGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security for worker node
      VpcId: !Ref emrVpc

  # The role and instance profile to attach to the EMR cluster
  emrInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: /
      Roles:
        - !Ref emrRole

  emrRole:
    Type: AWS::IAM::Role
    Properties:
      Path: /
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
        Version: '2012-10-17'
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceforEC2Role
      Policies:
        - PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "*"
                Resource: "*"

  # The service role used by EMR service
  emrServiceRole:
    Type: AWS::IAM::Role
    Properties:
      Path: /
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - elasticmapreduce.amazonaws.com
        Version: '2012-10-17'
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole

  # The security group to access Livy API
  lambdaSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      VpcId: !Ref emrVpc
      GroupDescription: Security group for Lambda function

  lambdaSecurityGroupIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref lambdaSecurityGroup
      IpProtocol: tcp
      FromPort: 8998
      ToPort: 8998
      SourceSecurityGroupId: !Ref lambdaSecurityGroup

  # The EMR cluster supporting notebook on Master node
  emrCluster:
    Type: AWS::EMR::Cluster
    Properties:
      Name:
        Fn::Join:
          - ''
          - - emr-cluster-
            - !GetAtt randomID.Value
      Instances:
        MasterInstanceGroup:
          InstanceCount: 1
          InstanceType: !Ref masterNodeType
          Market: ON_DEMAND
          Name: Master node
        CoreInstanceGroup:
          InstanceCount: !Ref workerNodeCount
          InstanceType: !Ref workerNodeType
          Market: ON_DEMAND
          Name: Core instance
        Ec2SubnetId: !Ref emrSubnet
        AdditionalMasterSecurityGroups:
          - !Ref lambdaSecurityGroup
        EmrManagedMasterSecurityGroup: !Ref emrMasterSecGroup
        EmrManagedSlaveSecurityGroup: !Ref emrWorkerSecGroup
      Applications:
        - Name: Hadoop
        - Name: Spark
        - Name: Livy
      Configurations:
        - Classification: spark
          ConfigurationProperties:
            maximizeResourceAllocation: 'false'
        - Classification: spark-defaults
          ConfigurationProperties:
            spark.executor.memory: '8G'
            spark.driver.memory: '2G'
            spark.dynamicAllocation.enabled: 'true'
            spark.executor.cores: 2
            spark.executor.instances: 12
            spark.sql.shuffle.partitions: 100
        - Classification: spark-hive-site
          ConfigurationProperties:
            hive.metastore.client.factory.class: 'com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory'
        - Classification: yarn-site
          ConfigurationProperties:
            yarn.resourcemanager.scheduler.class: 'org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler'
        - Classification: livy-conf
          ConfigurationProperties:
            livy.spark.deployMode: 'cluster'
      JobFlowRole: !Ref emrInstanceProfile
      ServiceRole: !Ref emrServiceRole
      ReleaseLabel: emr-5.24.0
      VisibleToAllUsers: true
      LogUri:
        Fn::Join:
          - ''
          - - s3://
            - !Ref emrLogBucket
            - "/logs/"

  # The bucket used to write data
  emrDataOutputBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName:
        Fn::Join:
          - ''
          - - emr-lab-output-
            - !GetAtt randomID.Value

  # The bucket used to store EMR logs
  emrLogBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName:
        Fn::Join:
          - ''
          - - emr-lab-log-
            - !GetAtt randomID.Value

  # The custom resource used to cleanup the buckets before deletion
  cleanupLogBucketOnDelete:
    Type: Custom::cleanupbucket
    DependsOn: emrLogBucket
    Properties:
      ServiceToken: !GetAtt cleanBucketFunction.Arn
      BucketName: !Ref emrLogBucket

  cleanupDataBucketOnDelete:
    Type: Custom::cleanupbucket
    DependsOn: emrDataOutputBucket
    Properties:
      ServiceToken: !GetAtt cleanBucketFunction.Arn
      BucketName: !Ref emrDataOutputBucket

  cleanBucketFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          #!/usr/bin/env python
          # -*- coding: utf-8 -*-

          import json
          import boto3
          from botocore.vendored import requests

          def handler(event, context):
              try:
                  bucket = event['ResourceProperties']['BucketName']

                  if event['RequestType'] == 'Delete':
                      s3 = boto3.resource('s3')
                      bucket = s3.Bucket(bucket)
                      for obj in bucket.objects.filter():
                          s3.Object(bucket.name, obj.key).delete()

                  sendResponseCfn(event, context, "SUCCESS")
              except Exception as e:
                  print(e)
                  sendResponseCfn(event, context, "FAILED")

          def sendResponseCfn(event, context, responseStatus):
              response_body = {'Status': responseStatus,
                              'Reason': 'Log stream name: ' + context.log_stream_name,
                              'PhysicalResourceId': context.log_stream_name,
                              'StackId': event['StackId'],
                              'RequestId': event['RequestId'],
                              'LogicalResourceId': event['LogicalResourceId'],
                              'Data': json.loads("{}")}

              requests.put(event['ResponseURL'], data=json.dumps(response_body))
      Handler: index.handler
      Runtime: python3.6
      Role: !GetAtt CleanBucketExecutionRole.Arn
      Timeout: 180

  CleanBucketExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: [lambda.amazonaws.com]
            Action: ['sts:AssumeRole']
      Path: /
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action: ['logs:*']
                Resource: 'arn:aws:logs:*:*:*'
        - PolicyName: s3Delete
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - s3:*
                Resource:
                  - '*'

  # The custom resource to delete EMR managed security groups from the VPC
  cleanupEmrWorkerSecgroup:
    Type: Custom::cleanupEmrWorkerSecgroup
    Properties:
      ServiceToken: !GetAtt cleanupEmrSecgroupFunction.Arn
      SecGroupName: !Ref emrWorkerSecGroup

  cleanupEmrMasterSecgroup:
    Type: Custom::cleanupEmrMasterSecgroup
    Properties:
      ServiceToken: !GetAtt cleanupEmrSecgroupFunction.Arn
      SecGroupName: !Ref emrMasterSecGroup

  cleanupEmrSecgroupFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: !Sub |
          #!/usr/bin/env python
          # -*- coding: utf-8 -*-

          import json
          import boto3
          from botocore.vendored import requests

          def handler(event, context):
              try:
                  sgName = event['ResourceProperties']['SecGroupName']

                  if event['RequestType'] == 'Delete':
                      ec2 = boto3.resource('ec2')
                      secgroup = ec2.SecurityGroup(sgName)
                      print("Deleting rules for SG " + str(secgroup))
                      secgroup.revoke_ingress(IpPermissions=secgroup.ip_permissions)

                  sendResponseCfn(event, context, "SUCCESS")
              except Exception as e:
                  print(e)
                  sendResponseCfn(event, context, "FAILED")

          def sendResponseCfn(event, context, responseStatus):
              response_body = {'Status': responseStatus,
                              'Reason': 'Log stream name: ' + context.log_stream_name,
                              'PhysicalResourceId': context.log_stream_name,
                              'StackId': event['StackId'],
                              'RequestId': event['RequestId'],
                              'LogicalResourceId': event['LogicalResourceId'],
                              'Data': json.loads("{}")}

              requests.put(event['ResponseURL'], data=json.dumps(response_body))

      Handler: index.handler
      Role: !GetAtt cleanupEmrSecgroupRole.Arn
      Runtime: python3.6
      Timeout: 60

  cleanupEmrSecgroupRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: "/"
      Policies:
        - PolicyName: LogsForLambda
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource:
                  - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*"
                  - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*:*"
        - PolicyName: EC2DescribeDeleleRevokeSg
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - ec2:Describe*
                  - ec2:DeleteSecurityGroup
                  - ec2:RevokeSecurityGroupIngress
                Resource: '*'
                Condition:
                  ArnEqualsIfExists:
                    ec2:Vpc: !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:vpc/${emrVpc}"

  # Step functions

  lambdaStateMachineRole:
    Type: AWS::IAM::Role
    Properties:
      Path: "/"
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AWSLambdaFullAccess
        - arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
        - arn:aws:iam::aws:policy/AWSStepFunctionsFullAccess

  stepFunctionsStateExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      Path: "/"
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - states.us-east-1.amazonaws.com
                - states.us-east-2.amazonaws.com
                - states.us-west-2.amazonaws.com
                - states.ap-northeast-1.amazonaws.com
                - states.ap-southeast-1.amazonaws.com
                - states.ap-southeast-2.amazonaws.com
                - states.ca-central-1.amazonaws.com
                - states.eu-central-1.amazonaws.com
                - states.eu-west-1.amazonaws.com
                - states.eu-west-2.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: state-execution-policy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - lambda:InvokeFunction
                Resource: "*"

  # the Lambda function to get job status
  sparkJobStatusFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.lambda_handler
      Role:
        Fn::GetAtt:
          - lambdaStateMachineRole
          - Arn
      Code:
        ZipFile:
          Fn::Join:
            - "\n"
            - - from botocore.vendored import requests
              - import json
              - 'def lambda_handler(event, context):'
              - "  jobid = event.get('jobId')"
              - Fn::Join:
                  - ''
                  - - "  url = 'http://"
                    - Fn::GetAtt:
                        - emrCluster
                        - MasterPublicDNS
                    - ":8998/batches/' + str(jobid)"
              - "  res = requests.get(url)"
              - "  json_data = json.loads(res.text)"
              - "  return json_data.get('state')"
      Runtime: python3.6
      Timeout: '25'
      TracingConfig:
        Mode: Active
      VpcConfig:
        SecurityGroupIds:
          - Ref: lambdaSecurityGroup
        SubnetIds:
          - Ref: emrSubnet

  # The Lambda function to submit the raw ride processing job
  rawRideJobSubmitFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.lambda_handler
      Role:
        Fn::GetAtt:
          - lambdaStateMachineRole
          - Arn
      Code:
        ZipFile:
          Fn::Join:
            - "\n"
            - - from botocore.vendored import requests
              - import json
              - 'def lambda_handler(event, context):'
              - '  headers = { "content-type": "application/json" }'
              - Fn::Join:
                  - ''
                  - - "  url = 'http://"
                    - Fn::GetAtt:
                        - emrCluster
                        - MasterPublicDNS
                    - ":8998/batches'"
              - "  if event.get('rawRidesColor') == 'yellow':"
              - "    shufflePart='80'"
              - "    execNum='8'"
              - "  else:"
              - "    shufflePart='20'"
              - "    execNum='2'"
              - "  payload = {"
              - "    'file' : 's3://aws-data-lake-workshop/emr-module/emr-lab/emr-lab-assembly-1.0.jar',"
              - "    'className' : 'RawRide',"
              - "    'args' : [event.get('rawRidesSource'), event.get('rawRidesColor'),event.get('rawRidesTarget')],"
              - "    'conf' : {'spark.sql.shuffle.partitions': shufflePart ,'spark.executor.instances': execNum}"
              - "  }"
              - "  res = requests.post(url, data = json.dumps(payload), headers = headers,
              verify = False)"
              - "  json_data = json.loads(res.text)"
              - "  return json_data.get('id')"
      Runtime: python3.6
      Timeout: '60'
      TracingConfig:
        Mode: Active
      VpcConfig:
        SecurityGroupIds:
          - Ref: lambdaSecurityGroup
        SubnetIds:
          - Ref: emrSubnet

  # The Lambda function to submit the merge zone with ride processing job
  mergeZoneRideJobSubmitFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.lambda_handler
      Role:
        Fn::GetAtt:
          - lambdaStateMachineRole
          - Arn
      Code:
        ZipFile:
          Fn::Join:
            - "\n"
            - - from botocore.vendored import requests
              - import json
              - 'def lambda_handler(event, context):'
              - '  headers = { "content-type": "application/json" }'
              - Fn::Join:
                  - ''
                  - - "  url = 'http://"
                    - Fn::GetAtt:
                        - emrCluster
                        - MasterPublicDNS
                    - ":8998/batches'"
              - "  payload = {"
              - "    'file' : 's3://aws-data-lake-workshop/emr-module/emr-lab/emr-lab-assembly-1.0.jar',"
              - "    'className' : 'MergeZoneRide',"
              - "    'args' : [event.get('yellowRawRides'), event.get('greenRawRides'), event.get('zoneSource'),event.get('mergeZoneRides')]"
              - "  }"
              - "  res = requests.post(url, data = json.dumps(payload), headers = headers,
              verify = False)"
              - "  json_data = json.loads(res.text)"
              - "  return json_data.get('id')"
      Runtime: python3.6
      Timeout: '60'
      TracingConfig:
        Mode: Active
      VpcConfig:
        SecurityGroupIds:
          - Ref: lambdaSecurityGroup
        SubnetIds:
          - Ref: emrSubnet

  # The Lambda function to submit the value zone job
  valueZoneJobSubmitFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.lambda_handler
      Role:
        Fn::GetAtt:
          - lambdaStateMachineRole
          - Arn
      Code:
        ZipFile:
          Fn::Join:
            - "\n"
            - - from botocore.vendored import requests
              - import json
              - 'def lambda_handler(event, context):'
              - '  headers = { "content-type": "application/json" }'
              - Fn::Join:
                  - ''
                  - - "  url = 'http://"
                    - Fn::GetAtt:
                        - emrCluster
                        - MasterPublicDNS
                    - ":8998/batches'"
              - "  payload = {"
              - "    'file' : 's3://aws-data-lake-workshop/emr-module/emr-lab/emr-lab-assembly-1.0.jar',"
              - "    'className' : 'ValueZone',"
              - "    'args' : [event.get('mergeZoneRides'),event.get('valueZones')]"
              - "  }"
              - "  res = requests.post(url, data = json.dumps(payload), headers = headers,
              verify = False)"
              - "  json_data = json.loads(res.text)"
              - "  return json_data.get('id')"
      Runtime: python3.6
      Timeout: '60'
      TracingConfig:
        Mode: Active
      VpcConfig:
        SecurityGroupIds:
          - Ref: lambdaSecurityGroup
        SubnetIds:
          - Ref: emrSubnet

  # The step function to orchestrate the pipeline
  emrPipelineStateMachine:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      DefinitionString:
        Fn::Sub:
          - |-
            {
              "Comment": "Raw ride taxi analysis pipeline on Amazon EMR with AWS Step Functions",
              "StartAt": "Pre-process",
              "States": {
                "Pre-process": {
                  "Type": "Pass",
                  "Next": "Parallel raw ride Jobs"
                },
                "Parallel raw ride Jobs": {
                  "Type": "Parallel",
                  "Branches": [
                    {
                      "StartAt": "Prep for yellow raw data",
                      "States": {
                        "Prep for yellow raw data": {
                          "Type": "Pass",
                          "Result": {"rawRidesColor" : "yellow","rawRidesSource" : "${yellowSource}","rawRidesTarget" : "${yellowRawRides}"},
                          "Next": "Yellow rawRide job launch"
                        },
                        "Yellow rawRide job launch": {
                          "Type": "Task",
                          "Resource": "${rawRideJobSubmitFunctionArn}",
                          "ResultPath": "$.jobId",
                          "Next": "Wait for yellow rawRide job to complete"
                        },
                        "Wait for yellow rawRide job to complete": {
                          "Type": "Wait",
                          "Seconds": 60,
                          "Next": "Query yellow rawRide job status"
                        },
                        "Query yellow rawRide job status": {
                          "Type": "Task",
                          "Resource": "${sparkJobStatusFunctionArn}",
                          "ResultPath": "$.jobStatus",
                          "Next": "Yellow rawRide job complete?"
                        },
                        "Yellow rawRide job complete?": {
                          "Type": "Choice",
                          "Choices": [
                            {
                              "Variable": "$.jobStatus",
                              "StringEquals": "success",
                              "Next": "Yellow rawRide job success"
                            },
                            {
                              "Variable": "$.jobStatus",
                              "StringEquals": "dead",
                              "Next": "Yellow rawRide job failed"
                            }
                          ],
                          "Default": "Wait for yellow rawRide job to complete"
                        },
                        "Yellow rawRide job failed": {
                          "Type": "Fail",
                          "Error": "Yellow rawRide Job",
                          "Cause": "Yellow rawRide job job did not complete successfully. Please check logs."
                        },
                        "Yellow rawRide job success": {
                          "Type": "Pass",
                          "End": true
                        }
                      }
                    },
                    {
                      "StartAt": "Prep for green raw data",
                      "States": {
                        "Prep for green raw data": {
                          "Type": "Pass",
                          "Result": {"rawRidesColor" : "green","rawRidesSource" : "${greenSource}","rawRidesTarget" : "${greenRawRides}"},
                          "Next": "Green rawRide job launch"
                        },
                        "Green rawRide job launch": {
                          "Type": "Task",
                          "Resource": "${rawRideJobSubmitFunctionArn}",
                          "ResultPath": "$.jobId",
                          "Next": "Wait for green rawRide job to complete"
                        },
                        "Wait for green rawRide job to complete": {
                          "Type": "Wait",
                          "Seconds": 60,
                          "Next": "Query green rawRide job status"
                        },
                        "Query green rawRide job status": {
                          "Type": "Task",
                          "Resource": "${sparkJobStatusFunctionArn}",
                          "ResultPath": "$.jobStatus",
                          "Next": "Green rawRide job complete?"
                        },
                        "Green rawRide job complete?": {
                          "Type": "Choice",
                          "Choices": [
                            {
                              "Variable": "$.jobStatus",
                              "StringEquals": "success",
                              "Next": "Green rawRide job success"
                            },
                            {
                              "Variable": "$.jobStatus",
                              "StringEquals": "dead",
                              "Next": "Green rawRide job failed"
                            }
                          ],
                          "Default": "Wait for green rawRide job to complete"
                        },
                        "Green rawRide job failed": {
                          "Type": "Fail",
                          "Error": "Green rawRide Job",
                          "Cause": "Green rawRide job job did not complete successfully. Please check logs."
                        },
                        "Green rawRide job success": {
                          "Type": "Pass",
                          "End": true
                        }
                      }
                    }
                  ],
                  "Next": "Prep for mergeZone job"
                },
                "Prep for mergeZone job": {
                  "Type": "Pass",
                  "Result": {"yellowRawRides" : "${yellowRawRides}","greenRawRides" : "${greenRawRides}","zoneSource" : "${zoneSource}","mergeZoneRides" : "${mergeZoneRides}" },
                  "Next": "MergeZoneRide job"
                },
                "MergeZoneRide job": {
                  "Type": "Task",
                  "Resource": "${mergeZoneRideSubmitFunctionArn}",
                  "ResultPath": "$.jobId",
                  "Next": "Wait for mergeZoneRide job to complete"
                },
                "Wait for mergeZoneRide job to complete": {
                  "Type": "Wait",
                  "Seconds": 60,
                  "Next": "Query mergeZoneRide job status"
                },
                "Query mergeZoneRide job status": {
                  "Type": "Task",
                  "Resource": "${sparkJobStatusFunctionArn}",
                  "ResultPath": "$.jobStatus",
                  "Next": "MergeZoneRide job complete?"
                },
                "MergeZoneRide job complete?": {
                  "Type": "Choice",
                  "Choices": [
                    {
                      "Variable": "$.jobStatus",
                      "StringEquals": "success",
                      "Next": "Prep for valueZone job"
                    },
                    {
                      "Variable": "$.jobStatus",
                      "StringEquals": "dead",
                      "Next": "MergeZoneRide job failed"
                    }
                  ],
                  "Default": "Wait for mergeZoneRide job to complete"
                },
                "MergeZoneRide job failed": {
                  "Type": "Fail",
                  "Error": "MergeZoneRide Job",
                  "Cause": "MergeZoneRide job did not complete successfully. Please check logs."
                },
                "Prep for valueZone job": {
                  "Type": "Pass",
                  "Result": {"mergeZoneRides" : "${mergeZoneRides}","valueZones" : "${valueZones}" },
                  "Next": "ValueZone job"
                },
                "ValueZone job": {
                  "Type": "Task",
                  "Resource": "${valueZoneJobSubmitFunctionArn}",
                  "ResultPath": "$.jobId",
                  "Next": "Wait for valueZone job to complete"
                },
                "Wait for valueZone job to complete": {
                  "Type": "Wait",
                  "Seconds": 60,
                  "Next": "Query valueZone job status"
                },
                "Query valueZone job status": {
                  "Type": "Task",
                  "Resource": "${sparkJobStatusFunctionArn}",
                  "ResultPath": "$.jobStatus",
                  "Next": "ValueZone job complete?"
                },
                "ValueZone job complete?": {
                  "Type": "Choice",
                  "Choices": [
                    {
                      "Variable": "$.jobStatus",
                      "StringEquals": "success",
                      "Next": "Pipeline finished"
                    },
                    {
                      "Variable": "$.jobStatus",
                      "StringEquals": "dead",
                      "Next": "ValueZone job failed"
                    }
                  ],
                  "Default": "Wait for valueZone job to complete"
                },
                "ValueZone job failed": {
                  "Type": "Fail",
                  "Error": "ValueZone Job",
                  "Cause": "ValueZone job did not complete successfully. Please check logs."
                },
                "Pipeline finished": {
                  "Type": "Pass",
                  "End": true
                }
              }
            }
          - {
            yellowSource : "s3://nyc-tlc/trip data/yellow_tripdata_2018*.csv",
            yellowRawRides: !Join [ "/", [ "s3:/", !Ref emrDataOutputBucket, "yellowRawRides" ] ],
            greenSource: "s3://nyc-tlc/trip data/green_tripdata_2018*.csv",
            greenRawRides: !Join [ "/", [ "s3:/", !Ref emrDataOutputBucket, "greenRawRides" ] ],
            rawRideJobSubmitFunctionArn: !GetAtt rawRideJobSubmitFunction.Arn,
            zoneSource: "s3://nyc-tlc/misc/taxi _zone_lookup.csv",
            sparkJobStatusFunctionArn: !GetAtt sparkJobStatusFunction.Arn,
            mergeZoneRides: !Join [ "/", [ "s3:/",!Ref emrDataOutputBucket, "mergeZoneRides" ] ],
            mergeZoneRideSubmitFunctionArn: !GetAtt mergeZoneRideJobSubmitFunction.Arn,
            valueZones: !Join [ "/", [ "s3:/",!Ref emrDataOutputBucket, "valueZones" ] ],
            valueZoneJobSubmitFunctionArn: !GetAtt valueZoneJobSubmitFunction.Arn
          }
      RoleArn:
        Fn::GetAtt:
          - stepFunctionsStateExecutionRole
          - Arn

Outputs:
  EMRBucket:
    Description: EMR data output dir
    Value: !Ref emrDataOutputBucket
  EMRLogBucket:
    Description: EMR log dir
    Value: !Ref emrLogBucket



